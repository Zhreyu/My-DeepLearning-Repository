{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BloodCellSegmentation using CNN(100% acc)\n",
        "Dataset: https://www.kaggle.com/datasets/jeetblahiri/bccd-dataset-with-mask"
      ],
      "metadata": {
        "id": "dyJFM49fqLvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tawLHjEOiasn",
        "outputId": "6af4e2c2-6416-415e-ee3f-5f063c876135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.32.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.5.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: tensorflow_io, opendatasets\n",
            "Successfully installed opendatasets-0.1.22 tensorflow_io-0.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets tensorflow_io matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/jeetblahiri/bccd-dataset-with-mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHil4Qepi6iW",
        "outputId": "0fdfefd2-c49c-421a-eefd-64627016e940"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bccd-dataset-with-mask.zip to ./bccd-dataset-with-mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.15G/2.15G [02:10<00:00, 17.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Set the paths to your dataset folders\n",
        "train_data_dir = '/content/bccd-dataset-with-mask/BCCD Dataset with mask/train'\n",
        "test_data_dir = '/content/bccd-dataset-with-mask/BCCD Dataset with mask/test'\n",
        "\n",
        "# Set the desired size for the images\n",
        "desired_width = 256\n",
        "desired_height = 256\n",
        "\n",
        "# Function to resize and save an image\n",
        "def preprocess_image(image_path, output_path):\n",
        "    image = Image.open(image_path)\n",
        "    resized_image = image.resize((desired_width, desired_height))\n",
        "    resized_image.save(output_path)\n",
        "\n",
        "# Preprocess the training data\n",
        "for root, dirs, files in os.walk(train_data_dir):\n",
        "    for file in files:\n",
        "        image_path = os.path.join(root, file)\n",
        "        output_path = os.path.join(root, 'resized_' + file)\n",
        "        preprocess_image(image_path, output_path)\n",
        "        os.remove(image_path)  # Remove the original image\n",
        "\n",
        "# Preprocess the testing data\n",
        "for root, dirs, files in os.walk(test_data_dir):\n",
        "    for file in files:\n",
        "        image_path = os.path.join(root, file)\n",
        "        output_path = os.path.join(root, 'resized_' + file)\n",
        "        preprocess_image(image_path, output_path)\n",
        "        os.remove(image_path)  # Remove the original image\n"
      ],
      "metadata": {
        "id": "L0TR1cETkNJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Set the path to one of your images\n",
        "image_path = '/content/bccd-dataset-with-mask/BCCD Dataset with mask/test/mask/resized_e5fd5949-4cd0-4cb6-837a-02c26a5eb87a.png'\n",
        "\n",
        "# Open the image using PIL\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Get the image dimensions\n",
        "width, height = image.size\n",
        "\n",
        "# Get the number of channels (e.g., 3 for RGB images)\n",
        "channels = len(image.getbands())\n",
        "\n",
        "# Print the values\n",
        "print(\"Image Width:\", width)\n",
        "print(\"Image Height:\", height)\n",
        "print(\"Number of Channels:\", channels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6f9QApelQvY",
        "outputId": "f4c3d87a-2d17-4726-dc36-f6695ff8cf18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Width: 256\n",
            "Image Height: 256\n",
            "Number of Channels: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the path to your dataset folders\n",
        "train_data_dir = '/content/bccd-dataset-with-mask/BCCD Dataset with mask/train'\n",
        "test_data_dir = '/content/bccd-dataset-with-mask/BCCD Dataset with mask/test'\n",
        "\n",
        "input_shape = (256,256,3)\n",
        "\n",
        "\n",
        "num_classes = 2  # mask and original\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "test_data = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and augment the training data\n",
        "train_generator = train_data.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load and rescale the testing data\n",
        "test_generator = test_data.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAdggzWZjA_X",
        "outputId": "794a9006-a40f-49df-d833-54a1a4067235"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2338 images belonging to 2 classes.\n",
            "Found 318 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "_rpRrrUxliK7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=5,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwJbdNzqliGy",
        "outputId": "f8b1b67c-eaba-4273-fea5-f136e66b83c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "74/74 [==============================] - 40s 537ms/step - loss: 9.0678e-06 - accuracy: 1.0000 - val_loss: 6.8065e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "74/74 [==============================] - 39s 532ms/step - loss: 6.6666e-06 - accuracy: 1.0000 - val_loss: 5.1213e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "74/74 [==============================] - 38s 520ms/step - loss: 5.1678e-06 - accuracy: 1.0000 - val_loss: 4.0365e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "74/74 [==============================] - 39s 523ms/step - loss: 4.1898e-06 - accuracy: 1.0000 - val_loss: 3.2901e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "74/74 [==============================] - 38s 520ms/step - loss: 3.4384e-06 - accuracy: 1.0000 - val_loss: 2.7612e-06 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d10b2e7dc60>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Ah94e_p1ba",
        "outputId": "212ff8cb-be03-4672-e961-c38cd0882b3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 98ms/step - loss: 2.7612e-06 - accuracy: 1.0000\n",
            "Test Loss: 2.7612322810455225e-06\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}